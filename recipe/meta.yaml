{% set version = "1.17.0" %}

package:
  name: onnx-split
  version: {{ version }}

source:
  url: https://github.com/onnx/onnx/archive/v{{ version }}.tar.gz
  sha256: 8d5e983c36037003615e5a02d36b18fc286541bf52de1a78f6cf9f32005a820e
  patches:
    # hmaarrfk - 202403
    # Unclear to me why we need this for windows, but not linux
    # it may be that the only parts that are needed are the absl::string
    # portions which in recent version of absl::c++17 just point to std::string
    # equivalents
    - patches/0001-Link-to-abseil_dll.patch                    # [win]
    - patches/0002-Let-conda-forge-define-CXX-standard.patch
    - patches/cinttypes_cpp2py_export.patch

build:
  number: 4

outputs:
  - name: libonnx
    script: build_libonnx.sh  # [unix]
    script: bld_libonnx.bat   # [win]
    build:
      run_exports:
        # No stable C API offered for onnx
        - {{ pin_subpackage('libonnx', max_pin='x.x.x') }}
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - cmake
        - make
        - libprotobuf
        # required to build the proto files
        - python=3.10
      host:
        - libprotobuf
      run_constrained:
        # Ensure that the libonnx package isn't installed with
        # older versions of the package
        - onnx {{ version }}=*_{{ build }}   # [version == "1.15.0"]
        - onnx {{ version }}                 # [version != "1.15.0"]
    test:
      commands:
        - test -f "$PREFIX/lib/libonnx${SHLIB_EXT}"  # [unix]
        - test -f "$PREFIX/lib/cmake/ONNX/ONNXConfig.cmake"  # [unix]
        - if not exist %PREFIX%\\Library\\bin\\onnx.dll exit 1   # [win]
        - if not exist %PREFIX%\\Library\\lib\\onnx.lib exit 1   # [win]
  - name: onnx
    script: build_onnx.sh  # [unix]
    script: bld_onnx.bat   # [win]
    build:
      entry_points:
        - check-model = onnx.bin.checker:check_model
        - check-node = onnx.bin.checker:check_node
        - backend-test-tools = onnx.backend.test.cmd_tools:main
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - numpy                                  # [build_platform != target_platform]
        - pybind11                               # [build_platform != target_platform]
        - libabseil                              # [build_platform != target_platform]
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - libprotobuf
        - cmake
        - make  # [unix]
      host:
        - python
        - setuptools
        - pip
        - protobuf
        - pytest-runner
        - ninja
        - pybind11
        - numpy
        - {{ pin_subpackage('libonnx', exact=True) }}
        - libprotobuf
        - libabseil  # [win]
      run:
        - python
        - protobuf
        - {{ pin_subpackage('libonnx', exact=True) }}
        - {{ pin_compatible('numpy') }}
        - typing-extensions >=3.6.2.1
    test:
      requires:
        - pip
      imports:
        - onnx
      commands:
        - pip check
        - check-model --help
        - check-node --help
        - backend-test-tools --help

about:
  home: https://github.com/onnx/onnx/
  license: Apache-2.0
  license_file: LICENSE
  summary: Open Neural Network Exchange library
  description: |
    Open Neural Network Exchange (ONNX) is the first step toward an open
    ecosystem that empowers AI developers to choose the right tools as their
    project evolves. ONNX provides an open source format for AI models. It
    defines an extensible computation graph model, as well as definitions of
    built-in operators and standard data types. Initially we focus on the
    capabilities needed for inferencing (evaluation).

extra:
  recipe-maintainers:
    - ezyang
    - marcelotrevisani
    - xhochy
    - janjagusch
    - cbourjau
