{% set name = "onnx" %}
{% set version = "1.14.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/onnx/onnx/archive/v{{ version }}.tar.gz
  sha256: e296f8867951fa6e71417a18f2e550a730550f8829bd35e947b4df5e3e777aa1
  patches:
    - 0001-Link-to-abseil_dll.patch  # [win and (libprotobuf != "3.21")]

build:
  number: 4
  entry_points:
    - check-model = onnx.bin.checker:check_model
    - check-node = onnx.bin.checker:check_node
    - backend-test-tools = onnx.backend.test.cmd_tools:main

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - numpy                                  # [build_platform != target_platform]
    - pybind11                               # [build_platform != target_platform]
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake
    - make
    - libprotobuf
    - sed  # [unix]
    - m2-sed  # [win]
  host:
    - python
    - pip
    - protobuf
    - libprotobuf
    - pytest-runner
    - ninja
    - pybind11
    - numpy
  run:
    - python
    - protobuf
    - {{ pin_compatible('numpy') }}
    - typing-extensions >=3.6.2.1

test:
  requires:
    - pip
  imports:
    - onnx
  commands:
    - pip check
    - check-model --help
    - check-node --help
    - backend-test-tools --help
    - test -f "$PREFIX/lib/libonnx${SHLIB_EXT}"  # [unix]
    - test -f "$PREFIX/lib/cmake/ONNX/ONNXConfig.cmake"  # [unix]

about:
  home: https://github.com/onnx/onnx/
  license: Apache-2.0
  license_file: LICENSE
  summary: Open Neural Network Exchange library
  description: |
    Open Neural Network Exchange (ONNX) is the first step toward an open
    ecosystem that empowers AI developers to choose the right tools as their
    project evolves. ONNX provides an open source format for AI models. It
    defines an extensible computation graph model, as well as definitions of
    built-in operators and standard data types. Initially we focus on the
    capabilities needed for inferencing (evaluation).

extra:
  recipe-maintainers:
    - ezyang
    - marcelotrevisani
    - xhochy
    - janjagusch
    - cbourjau
